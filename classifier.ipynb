{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uneccessary on google colab\n",
    "# %conda install pytorch torchvision -c pytorch\n",
    "# %conda install -c fastai fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cat v dog single-label classification example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "file_names = get_image_files(path/'images')\n",
    "\n",
    "def label_func(filename):\n",
    "    return \"cat\" if filename.name[0].isupper() else \"dog\"\n",
    "\n",
    "dblock = DataBlock(blocks    = (ImageBlock, CategoryBlock),\n",
    "                   get_items = get_image_files,\n",
    "                   get_y     = label_func,\n",
    "                   splitter  = RandomSplitter(),\n",
    "                   item_tfms = Resize(224))\n",
    "\n",
    "dls = dblock.dataloaders(path/\"images\")\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining ResNet34 on new labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the performance of retrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(6,6))\n",
    "interp.plot_top_losses(9, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PILImage.create(file_names[9])\n",
    "\n",
    "prediction,_,probs = learn.predict(img)\n",
    "\n",
    "print(f\"Predicted animal: {prediction}.\")\n",
    "print(f\"Probability it is this animal: {probs[1].item():.6f}\")\n",
    "img.to_thumb(192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain for single-label Chest cancer classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/davay/data5100.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label and load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data5100/data'\n",
    "dls = ImageDataLoaders.from_folder(path,\n",
    "                            train = 'train',\n",
    "                            valid = 'valid',\n",
    "                            test = 'test',\n",
    "                            item_tfms = Resize(224, pad_mode='zeros'), # imagenet models often use 224 x 224. Our images aren't 1:1 aspect ratio, by default center crop will be used. We can add pad_mode='zeros' for no cropping.\n",
    "                            batch_tfms=aug_transforms()) # testing default augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the accuracy of stock imagenet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: IN PROGRESS\n",
    "\n",
    "# model = resnet34(pretrained = True)\n",
    "\n",
    "# # switch to evaluation mode for inference rather than training\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain model on new data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the accuracy of retrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(6,6))\n",
    "interp.plot_top_losses(9, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = get_image_files(path)\n",
    "img = PILImage.create(file_names[random.randint(0, len(file_names)) - 1])\n",
    "\n",
    "prediction,_,probs = learn.predict(img)\n",
    "\n",
    "print(f\"Predicted picture: {prediction}.\")\n",
    "print(f\"Probability: {probs[1].item():.6f}\")\n",
    "img.to_thumb(192)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
