{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0oz-G2uvBJp"
      },
      "outputs": [],
      "source": [
        "# Unnecessary on google colab\n",
        "# %conda install pytorch torchvision -c pytorch\n",
        "# %conda install -c fastai fastai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUMYR-V5vBJu"
      },
      "source": [
        "## Single-label chest cancer classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import and clone dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTiAUfHUvBJu",
        "outputId": "27139275-99cb-411b-b175-53ae44327432"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/davay/.conda/envs/data5100/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from fastai.vision.all import *\n",
        "from fastcore.all import *\n",
        "from fastai.callback.tracker import EarlyStoppingCallback\n",
        "from sklearn.metrics import f1_score\n",
        "# !git clone https://github.com/davay/data5100.git # unnecessary on local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf0SPfJavBJu"
      },
      "source": [
        "### Label and load images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0MsZu7NRvBJu"
      },
      "outputs": [],
      "source": [
        "path = 'data' # local\n",
        "# path = 'data5100/data' # google colab\n",
        "dls = ImageDataLoaders.from_folder(path,\n",
        "                            train = 'train',\n",
        "                            valid = 'valid',\n",
        "                            test = 'test',\n",
        "                            item_tfms = Resize(450, pad_mode='zeros'),\n",
        "                            # item_tfms = RandomResizedCrop(450, min_scale = 0.75), # imagenet models often use 224 x 224. Our images aren't 1:1 aspect ratio, by default center crop will be used. We can add pad_mode='zeros' for no cropping.\n",
        "                            batch_tfms=[*aug_transforms(size=224, max_warp=0.), Normalize.from_stats(*imagenet_stats)],\n",
        "                            bs=32) # default is 64, local runs out of memory when used with densenet201"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKP5U52vvBJu"
      },
      "source": [
        "### Retrain model on new data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "UOxoXI8VvBJu",
        "outputId": "2538a3a7-ad60-4b13-e799-c76353d05114"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='2' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      33.33% [2/6 00:08&lt;00:16]\n",
              "    </div>\n",
              "    \n",
              "\n",
              "\n",
              "    <div>\n",
              "      <progress value='16' class='' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      84.21% [16/19 00:03&lt;00:00 1.7705]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/davay/Repos/data5100/classifier.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m learn \u001b[39m=\u001b[39m vision_learner(dls, densenet201, metrics\u001b[39m=\u001b[39merror_rate)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m lr_valley \u001b[39m=\u001b[39m learn\u001b[39m.\u001b[39;49mlr_find()\u001b[39m.\u001b[39mvalley\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m epoch \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m div \u001b[39m=\u001b[39m \u001b[39m25\u001b[39m\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/callback/schedule.py:293\u001b[0m, in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggest_funcs)\u001b[0m\n\u001b[1;32m    291\u001b[0m n_epoch \u001b[39m=\u001b[39m num_it\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mtrain) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    292\u001b[0m cb\u001b[39m=\u001b[39mLRFinder(start_lr\u001b[39m=\u001b[39mstart_lr, end_lr\u001b[39m=\u001b[39mend_lr, num_it\u001b[39m=\u001b[39mnum_it, stop_div\u001b[39m=\u001b[39mstop_div)\n\u001b[0;32m--> 293\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno_logging(): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(n_epoch, cbs\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m suggest_funcs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     lrs, losses \u001b[39m=\u001b[39m tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecorder\u001b[39m.\u001b[39mlrs[num_it\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m]), tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecorder\u001b[39m.\u001b[39mlosses[num_it\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m])\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/learner.py:264\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mset_hypers(lr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr \u001b[39mif\u001b[39;00m lr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m lr)\n\u001b[1;32m    263\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epoch \u001b[39m=\u001b[39m n_epoch\n\u001b[0;32m--> 264\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_fit, \u001b[39m'\u001b[39;49m\u001b[39mfit\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelFitException, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_end_cleanup)\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    200\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/learner.py:253\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epoch):\n\u001b[1;32m    252\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch\u001b[39m=\u001b[39mepoch\n\u001b[0;32m--> 253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_epoch, \u001b[39m'\u001b[39;49m\u001b[39mepoch\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelEpochException)\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    200\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/learner.py:247\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_epoch\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 247\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_epoch_train()\n\u001b[1;32m    248\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_epoch_validate()\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/learner.py:239\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_epoch_train\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    238\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mtrain\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mall_batches, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelTrainException)\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    200\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/learner.py:205\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mall_batches\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl)\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mone_batch(\u001b[39m*\u001b[39;49mo)\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/learner.py:235\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    233\u001b[0m b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_device(b)\n\u001b[1;32m    234\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(b)\n\u001b[0;32m--> 235\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_one_batch, \u001b[39m'\u001b[39;49m\u001b[39mbatch\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelBatchException)\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    200\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/learner.py:223\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39mself\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mafter_loss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39myb): \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_grad_opt()\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/learner.py:211\u001b[0m, in \u001b[0;36mLearner._do_grad_opt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_grad_opt\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 211\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backward, \u001b[39m'\u001b[39;49m\u001b[39mbackward\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelBackwardException)\n\u001b[1;32m    212\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_with_events(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step, \u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m, CancelStepException)\n\u001b[1;32m    213\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    200\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/learner.py:207\u001b[0m, in \u001b[0;36mLearner._backward\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m--> 207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_backward\u001b[39m(\u001b[39mself\u001b[39m): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_grad\u001b[39m.\u001b[39;49mbackward()\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_tensor.py:483\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \n\u001b[1;32m    438\u001b[0m \u001b[39mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[39m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39;49mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39;49m,),\n\u001b[1;32m    486\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    487\u001b[0m         gradient\u001b[39m=\u001b[39;49mgradient,\n\u001b[1;32m    488\u001b[0m         retain_graph\u001b[39m=\u001b[39;49mretain_graph,\n\u001b[1;32m    489\u001b[0m         create_graph\u001b[39m=\u001b[39;49mcreate_graph,\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[1;32m    492\u001b[0m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39minputs\n\u001b[1;32m    494\u001b[0m )\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/overrides.py:1577\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1572\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mwill be an error in future, please define it as a classmethod.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1573\u001b[0m                   \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   1575\u001b[0m \u001b[39m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m \u001b[39m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[0;32m-> 1577\u001b[0m result \u001b[39m=\u001b[39m torch_func_method(public_api, types, args, kwargs)\n\u001b[1;32m   1579\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1580\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/torch_core.py:382\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mdebug \u001b[39mand\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39m__str__\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m__repr__\u001b[39m\u001b[39m'\u001b[39m): \u001b[39mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m _torch_handled(args, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_opt, func): types \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mTensor,)\n\u001b[0;32m--> 382\u001b[0m res \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m__torch_function__(func, types, args, ifnone(kwargs, {}))\n\u001b[1;32m    383\u001b[0m dict_objs \u001b[39m=\u001b[39m _find_args(args) \u001b[39mif\u001b[39;00m args \u001b[39melse\u001b[39;00m _find_args(\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mvalues()))\n\u001b[1;32m    384\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mtype\u001b[39m(res),TensorBase) \u001b[39mand\u001b[39;00m dict_objs: res\u001b[39m.\u001b[39mset_meta(dict_objs[\u001b[39m0\u001b[39m],as_copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_tensor.py:1386\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1383\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m   1385\u001b[0m \u001b[39mwith\u001b[39;00m _C\u001b[39m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1386\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1387\u001b[0m     \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1388\u001b[0m         \u001b[39mreturn\u001b[39;00m ret\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "learn = vision_learner(dls, densenet201, metrics=error_rate)\n",
        "lr_valley = learn.lr_find().valley\n",
        "epoch = 50\n",
        "div = 25\n",
        "# learn.fit_one_cycle(epoch, lr_valley)\n",
        "learn.fit_one_cycle(epoch, lr_valley, div, cbs=[EarlyStoppingCallback(monitor='valid_loss', min_delta=0.01, patience=3)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuGIO1pDvBJu"
      },
      "source": [
        "### Evaluate performance of retrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M95jgT9IvBJu",
        "outputId": "710b099c-cf16-4be2-8641-707d512929cd"
      },
      "outputs": [],
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix(figsize=(6,6))\n",
        "interp.plot_top_losses(9, figsize=(15,10)) # TODO: fix overlapping text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a custom F1 score metric for Fastai\n",
        "f1score_fastai = skm_to_fastai(f1_score, average='macro')\n",
        "\n",
        "# Append the F1 score metric\n",
        "learn.metrics.append(f1score_fastai)\n",
        "\n",
        "# Validate and print F1 Score\n",
        "val_f1score = learn.recorder.values[-1][2]  # Index 2 corresponds to the F1 score\n",
        "\n",
        "print(f\"F1 Score: {val_f1score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Automated Runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######################################\n",
            "RUN: 1\n",
            "BASE MODEL: resnet152\n",
            "FIT OPTION: {'method': 'fine_tune', 'n_epoch': 50}\n",
            "ITEM TFMS: Resize(224)\n",
            "BATCH TFMS: None\n",
            "######################################\n",
            "Could not do one pass in your dataloader, there is something wrong in it. Please see the stack trace below:\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/home/davay/Repos/data5100/classifier.ipynb Cell 13\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X15sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m exec(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mitem_tfms_obj = \u001b[39m\u001b[39m{\u001b[39;00mitem_tfms\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39m# Hacky way to grab the pre-evaluated option for cleaner output\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X15sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m exec(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch_tfms_obj = \u001b[39m\u001b[39m{\u001b[39;00mbatch_tfms\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X15sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m dls \u001b[39m=\u001b[39m ImageDataLoaders\u001b[39m.\u001b[39;49mfrom_folder(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X15sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     path,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X15sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     train\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X15sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     valid\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mvalid\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X15sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     test\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X15sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     item_tfms\u001b[39m=\u001b[39;49mitem_tfms_obj,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X15sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     batch_tfms\u001b[39m=\u001b[39;49mbatch_tfms_obj,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X15sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     bs\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m) \u001b[39m# default batch size is 64, local runs out of memory sometimes\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X15sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39m# Modelling\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/davay/Repos/data5100/classifier.ipynb#X15sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m learn \u001b[39m=\u001b[39m vision_learner(dls, base_model, metrics\u001b[39m=\u001b[39merror_rate)\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/vision/data.py:123\u001b[0m, in \u001b[0;36mImageDataLoaders.from_folder\u001b[0;34m(cls, path, train, valid, valid_pct, seed, vocab, item_tfms, batch_tfms, img_cls, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m get_items \u001b[39m=\u001b[39m get_image_files \u001b[39mif\u001b[39;00m valid_pct \u001b[39melse\u001b[39;00m partial(get_image_files, folders\u001b[39m=\u001b[39m[train, valid])\n\u001b[1;32m    117\u001b[0m dblock \u001b[39m=\u001b[39m DataBlock(blocks\u001b[39m=\u001b[39m(ImageBlock(img_cls), CategoryBlock(vocab\u001b[39m=\u001b[39mvocab)),\n\u001b[1;32m    118\u001b[0m                    get_items\u001b[39m=\u001b[39mget_items,\n\u001b[1;32m    119\u001b[0m                    splitter\u001b[39m=\u001b[39msplitter,\n\u001b[1;32m    120\u001b[0m                    get_y\u001b[39m=\u001b[39mparent_label,\n\u001b[1;32m    121\u001b[0m                    item_tfms\u001b[39m=\u001b[39mitem_tfms,\n\u001b[1;32m    122\u001b[0m                    batch_tfms\u001b[39m=\u001b[39mbatch_tfms)\n\u001b[0;32m--> 123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_dblock(dblock, path, path\u001b[39m=\u001b[39;49mpath, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/data/core.py:284\u001b[0m, in \u001b[0;36mDataLoaders.from_dblock\u001b[0;34m(cls, dblock, source, path, bs, val_bs, shuffle, device, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_dblock\u001b[39m(\u001b[39mcls\u001b[39m, \n\u001b[1;32m    275\u001b[0m     dblock, \u001b[39m# `DataBlock` object\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    283\u001b[0m ):\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m dblock\u001b[39m.\u001b[39;49mdataloaders(source, path\u001b[39m=\u001b[39;49mpath, bs\u001b[39m=\u001b[39;49mbs, val_bs\u001b[39m=\u001b[39;49mval_bs, shuffle\u001b[39m=\u001b[39;49mshuffle, device\u001b[39m=\u001b[39;49mdevice, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/data/block.py:157\u001b[0m, in \u001b[0;36mDataBlock.dataloaders\u001b[0;34m(self, source, path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m dsets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatasets(source, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[1;32m    156\u001b[0m kwargs \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, \u001b[39m'\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m'\u001b[39m: verbose}\n\u001b[0;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m dsets\u001b[39m.\u001b[39;49mdataloaders(path\u001b[39m=\u001b[39;49mpath, after_item\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitem_tfms, after_batch\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_tfms, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/data/core.py:337\u001b[0m, in \u001b[0;36mFilteredBase.dataloaders\u001b[0;34m(self, bs, shuffle_train, shuffle, val_shuffle, n, path, dl_type, dl_kwargs, device, drop_last, val_bs, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m dl \u001b[39m=\u001b[39m dl_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubset(\u001b[39m0\u001b[39m), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmerge(kwargs,def_kwargs, dl_kwargs[\u001b[39m0\u001b[39m]))\n\u001b[1;32m    336\u001b[0m def_kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mbs\u001b[39m\u001b[39m'\u001b[39m:bs \u001b[39mif\u001b[39;00m val_bs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m val_bs,\u001b[39m'\u001b[39m\u001b[39mshuffle\u001b[39m\u001b[39m'\u001b[39m:val_shuffle,\u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mNone\u001b[39;00m,\u001b[39m'\u001b[39m\u001b[39mdrop_last\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mFalse\u001b[39;00m}\n\u001b[0;32m--> 337\u001b[0m dls \u001b[39m=\u001b[39m [dl] \u001b[39m+\u001b[39m [dl\u001b[39m.\u001b[39;49mnew(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubset(i), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmerge(kwargs,def_kwargs,val_kwargs,dl_kwargs[i]))\n\u001b[1;32m    338\u001b[0m               \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m1\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_subsets)]\n\u001b[1;32m    339\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dbunch_type(\u001b[39m*\u001b[39mdls, path\u001b[39m=\u001b[39mpath, device\u001b[39m=\u001b[39mdevice)\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/data/core.py:337\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    335\u001b[0m dl \u001b[39m=\u001b[39m dl_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubset(\u001b[39m0\u001b[39m), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmerge(kwargs,def_kwargs, dl_kwargs[\u001b[39m0\u001b[39m]))\n\u001b[1;32m    336\u001b[0m def_kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mbs\u001b[39m\u001b[39m'\u001b[39m:bs \u001b[39mif\u001b[39;00m val_bs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m val_bs,\u001b[39m'\u001b[39m\u001b[39mshuffle\u001b[39m\u001b[39m'\u001b[39m:val_shuffle,\u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mNone\u001b[39;00m,\u001b[39m'\u001b[39m\u001b[39mdrop_last\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mFalse\u001b[39;00m}\n\u001b[0;32m--> 337\u001b[0m dls \u001b[39m=\u001b[39m [dl] \u001b[39m+\u001b[39m [dl\u001b[39m.\u001b[39;49mnew(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubset(i), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmerge(kwargs,def_kwargs,val_kwargs,dl_kwargs[i]))\n\u001b[1;32m    338\u001b[0m               \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_subsets)]\n\u001b[1;32m    339\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dbunch_type(\u001b[39m*\u001b[39mdls, path\u001b[39m=\u001b[39mpath, device\u001b[39m=\u001b[39mdevice)\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/data/core.py:97\u001b[0m, in \u001b[0;36mTfmdDL.new\u001b[0;34m(self, dataset, cls, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_n_inp\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_types\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     96\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_one_pass()\n\u001b[1;32m     98\u001b[0m         res\u001b[39m.\u001b[39m_n_inp,res\u001b[39m.\u001b[39m_types \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_inp,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_types\n\u001b[1;32m     99\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e: \n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/data/core.py:79\u001b[0m, in \u001b[0;36mTfmdDL._one_pass\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_one_pass\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     78\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_batch([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_item(\u001b[39mNone\u001b[39;00m)])\n\u001b[0;32m---> 79\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: b \u001b[39m=\u001b[39m to_device(b, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     80\u001b[0m     its \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter_batch(b)\n\u001b[1;32m     81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_inp \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(its, (\u001b[39mlist\u001b[39m,\u001b[39mtuple\u001b[39m)) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(its)\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(its)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/torch_core.py:285\u001b[0m, in \u001b[0;36mto_device\u001b[0;34m(b, device, non_blocking)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(o,Tensor): \u001b[39mreturn\u001b[39;00m o\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39mnon_blocking)\n\u001b[1;32m    284\u001b[0m     \u001b[39mreturn\u001b[39;00m o\n\u001b[0;32m--> 285\u001b[0m \u001b[39mreturn\u001b[39;00m apply(_inner, b)\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/torch_core.py:222\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(func, x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mApply `func` recursively to `x`, passing on args\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 222\u001b[0m     \u001b[39mif\u001b[39;00m is_listy(x): \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(x)([apply(func, o, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mfor\u001b[39;49;00m o \u001b[39min\u001b[39;49;00m x])\n\u001b[1;32m    223\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x,(\u001b[39mdict\u001b[39m,MutableMapping)): \u001b[39mreturn\u001b[39;00m {k: apply(func, v, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    224\u001b[0m     res \u001b[39m=\u001b[39m func(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/torch_core.py:222\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(func, x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mApply `func` recursively to `x`, passing on args\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 222\u001b[0m     \u001b[39mif\u001b[39;00m is_listy(x): \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(x)([apply(func, o, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m x])\n\u001b[1;32m    223\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x,(\u001b[39mdict\u001b[39m,MutableMapping)): \u001b[39mreturn\u001b[39;00m {k: apply(func, v, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    224\u001b[0m     res \u001b[39m=\u001b[39m func(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/torch_core.py:224\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m is_listy(x): \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(x)([apply(func, o, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m x])\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x,(\u001b[39mdict\u001b[39m,MutableMapping)): \u001b[39mreturn\u001b[39;00m {k: apply(func, v, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m--> 224\u001b[0m res \u001b[39m=\u001b[39m func(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    225\u001b[0m \u001b[39mreturn\u001b[39;00m res \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m retain_type(res, x)\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/torch_core.py:283\u001b[0m, in \u001b[0;36mto_device.<locals>._inner\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_inner\u001b[39m(o):\n\u001b[1;32m    282\u001b[0m     \u001b[39m# ToDo: add TensorDict when released\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(o,Tensor): \u001b[39mreturn\u001b[39;00m o\u001b[39m.\u001b[39;49mto(device, non_blocking\u001b[39m=\u001b[39;49mnon_blocking)\n\u001b[1;32m    284\u001b[0m     \u001b[39mreturn\u001b[39;00m o\n",
            "File \u001b[0;32m~/.conda/envs/data5100/lib/python3.11/site-packages/fastai/torch_core.py:382\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mdebug \u001b[39mand\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39m__str__\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m__repr__\u001b[39m\u001b[39m'\u001b[39m): \u001b[39mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m _torch_handled(args, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_opt, func): types \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mTensor,)\n\u001b[0;32m--> 382\u001b[0m res \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m__torch_function__(func, types, args, ifnone(kwargs, {}))\n\u001b[1;32m    383\u001b[0m dict_objs \u001b[39m=\u001b[39m _find_args(args) \u001b[39mif\u001b[39;00m args \u001b[39melse\u001b[39;00m _find_args(\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mvalues()))\n\u001b[1;32m    384\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mtype\u001b[39m(res),TensorBase) \u001b[39mand\u001b[39;00m dict_objs: res\u001b[39m.\u001b[39mset_meta(dict_objs[\u001b[39m0\u001b[39m],as_copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_tensor.py:1386\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1383\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m   1385\u001b[0m \u001b[39mwith\u001b[39;00m _C\u001b[39m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1386\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1387\u001b[0m     \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1388\u001b[0m         \u001b[39mreturn\u001b[39;00m ret\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "from fastai.vision.all import *\n",
        "from fastcore.all import *\n",
        "from fastai.callback.tracker import EarlyStoppingCallback\n",
        "from sklearn.metrics import f1_score\n",
        "import gc \n",
        "\n",
        "base_models = [\n",
        "    # resnet18,\n",
        "    # resnet50,\n",
        "    resnet152,\n",
        "    # densenet121, \n",
        "    densenet201,\n",
        "    ]\n",
        "\n",
        "fit_options = [\n",
        "    {\"method\": \"fine_tune\", \"n_epoch\": 50}, \n",
        "    {\"method\": \"fit_one_cycle\", \"n_epoch\": 50},\n",
        "    {\"method\": \"fit_one_cycle\", \"n_epoch\": 50, \"lr_max\": \"lr_find().valley\", \"early_stop\": {\"patience\": 3}},\n",
        "    {\"method\": \"fit_one_cycle\", \"n_epoch\": 50, \"lr_max\": \"lr_find().valley\", \"div\": 10, \"early_stop\": {\"patience\": 3}}, # this is per resnet paper <link>\n",
        "    {\"method\": \"fit_one_cycle\", \"n_epoch\": 50, \"lr_max\": \"lr_find().valley\", \"early_stop\": {\"patience\": 10}},\n",
        "]\n",
        "\n",
        "item_tfms_options = [\n",
        "    \"Resize(224)\", # using default center crop\n",
        "    \"Resize(224, pad_mode='zeros')\",\n",
        "    # \"Resize(450, pad_mode='zeros')\",\n",
        "    # \"RandomResizedCrop(450, min_scale=0.75)\" # from fastai paper https://arxiv.org/abs/2002.04688\n",
        "    ]\n",
        "\n",
        "batch_tfms_options = [\n",
        "    \"None\",\n",
        "    \"aug_transforms()\", \n",
        "    \"[*aug_transforms(size=224, max_warp=0.), Normalize.from_stats(*imagenet_stats)]\" # from fastai paper https://arxiv.org/abs/2002.04688\n",
        "    ]\n",
        "\n",
        "def evaluate(learner):\n",
        "    f1score_fastai = skm_to_fastai(f1_score, average='macro')\n",
        "    learner.metrics.append(f1score_fastai)\n",
        "    f1 = learner.recorder.values[-1][2] # Index 2 corresponds to the F1 score\n",
        "    return f1\n",
        "\n",
        "path = 'data' # local\n",
        "# path = 'data5100/data' # google colab\n",
        "\n",
        "# Iterate over all combinations\n",
        "n = 1\n",
        "for base_model in base_models:\n",
        "    \n",
        "    # Initialize new data frame per base model, we will separate the csv because there is a chance some runs intermittently fail after a few hundred runs\n",
        "    results = pd.DataFrame(columns=[\"Base Model\", \"Fit Method\", \"n_epoch\", \"lr_max\", \"div\", \"patience\", \"item_tfms\", \"batch_tfms\", \"F1 Score\"])\n",
        "\n",
        "    for fit_option in fit_options:\n",
        "        for batch_tfms in batch_tfms_options:\n",
        "            for item_tfms in item_tfms_options:\n",
        "                print(\"######################################\")\n",
        "                print(f\"RUN: {n}\")\n",
        "                print(f\"BASE MODEL: {base_model.__name__}\") \n",
        "                print(f\"FIT OPTION: {fit_option}\")\n",
        "                print(f\"ITEM TFMS: {item_tfms}\") \n",
        "                print(f\"BATCH TFMS: {batch_tfms}\")\n",
        "                print(\"######################################\")\n",
        "                n += 1\n",
        "\n",
        "                # Data Prep\n",
        "                exec(f\"item_tfms_obj = {item_tfms}\") # Hacky way to grab the pre-evaluated option for cleaner output\n",
        "                exec(f\"batch_tfms_obj = {batch_tfms}\")\n",
        "                dls = ImageDataLoaders.from_folder(\n",
        "                    path,\n",
        "                    train='train',\n",
        "                    valid='valid',\n",
        "                    test='test',\n",
        "                    item_tfms=item_tfms_obj,\n",
        "                    batch_tfms=batch_tfms_obj,\n",
        "                    bs=32) # default batch size is 64, local runs out of memory sometimes\n",
        "                \n",
        "                # Modelling\n",
        "                learn = vision_learner(dls, base_model, metrics=error_rate)\n",
        "\n",
        "                with learn.no_bar(), learn.no_logging():\n",
        "                    lr_valley = learn.lr_find().valley if fit_option.get(\"lr_max\", None) == \"lr_find().valley\" else None;\n",
        "                    early_stop_params = fit_option.get(\"early_stop\", None)\n",
        "                    cbs = EarlyStoppingCallback(\n",
        "                        monitor='valid_loss', \n",
        "                        min_delta=0.01, \n",
        "                        patience=early_stop_params.get(\"patience\", 1) # default patience value is 1 - shouldn't get used tho\n",
        "                    ) if early_stop_params else None\n",
        "                    div = fit_option.get(\"div\", 25)\n",
        "                    if fit_option[\"method\"] == \"fit_one_cycle\":\n",
        "                        learn.fit_one_cycle(fit_option[\"n_epoch\"], lr_valley, div=div if div else None, cbs=cbs if cbs else None)\n",
        "                    if fit_option[\"method\"] == \"fine_tune\":\n",
        "                        learn.fine_tune(fit_option[\"n_epoch\"])\n",
        "\n",
        "                # Evaluation\n",
        "                f1 = evaluate(learn)\n",
        "                results = pd.concat([results, pd.DataFrame([{\n",
        "                    \"Base Model\": base_model.__name__,\n",
        "                    \"Fit Method\": fit_option[\"method\"],\n",
        "                    \"n_epoch\": fit_option[\"n_epoch\"],\n",
        "                    \"lr_max\": str(fit_option.get(\"lr_max\", None)) + f\" -> {lr_valley}\",\n",
        "                    \"div\": fit_option.get(\"div\", 25),\n",
        "                    \"patience\": fit_option[\"early_stop\"][\"patience\"] if fit_option.get(\"early_stop\", None) else 1, # TODO: TECHNICALLYYYY patience should be None in output if early stop dont exist, because it dont get used\n",
        "                    \"item_tfms\": item_tfms,\n",
        "                    \"batch_tfms\": batch_tfms,\n",
        "                    \"F1 Score\": f1\n",
        "                }])], ignore_index=True)\n",
        "                \n",
        "                # Reclaim GPU memory\n",
        "                learn = None\n",
        "                gc.collect()\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    results.to_csv(f\"{base_model.__name__}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reclaim GPU memory\n",
        "import gc\n",
        "learn = None\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
