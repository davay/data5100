{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0oz-G2uvBJp"
      },
      "outputs": [],
      "source": [
        "# Unnecessary on google colab, run this to install on local\n",
        "%conda install pytorch torchvision -c pytorch\n",
        "%conda install -c fastai fastai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUMYR-V5vBJu"
      },
      "source": [
        "## Manual step-by-step\n",
        "\n",
        "The code below has the parameters for the best model we were able to produce."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import and clone dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTiAUfHUvBJu",
        "outputId": "27139275-99cb-411b-b175-53ae44327432"
      },
      "outputs": [],
      "source": [
        "from fastai.vision.all import *\n",
        "from fastcore.all import *\n",
        "from fastai.callback.tracker import EarlyStoppingCallback\n",
        "from sklearn.metrics import f1_score\n",
        "# !git clone https://github.com/davay/data5100.git # unnecessary on local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf0SPfJavBJu"
      },
      "source": [
        "### Label and load images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MsZu7NRvBJu"
      },
      "outputs": [],
      "source": [
        "path = 'data' # local\n",
        "# path = 'data5100/data' # google colab\n",
        "dls = ImageDataLoaders.from_folder(path,\n",
        "                            train = 'train',\n",
        "                            valid = 'valid',\n",
        "                            test = 'test',\n",
        "                            item_tfms = Resize(450, pad_mode='zeros'),\n",
        "                            # item_tfms = RandomResizedCrop(450, min_scale = 0.75), # imagenet models often use 224 x 224. Our images aren't 1:1 aspect ratio, by default center crop will be used. We can add pad_mode='zeros' for no cropping.\n",
        "                            batch_tfms=[*aug_transforms(size=224, max_warp=0.), Normalize.from_stats(*imagenet_stats)],\n",
        "                            bs=32) # default is 64, local runs out of memory when used with densenet201"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKP5U52vvBJu"
      },
      "source": [
        "### Retrain model on new data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "UOxoXI8VvBJu",
        "outputId": "2538a3a7-ad60-4b13-e799-c76353d05114"
      },
      "outputs": [],
      "source": [
        "learn = vision_learner(dls, densenet201, metrics=error_rate)\n",
        "lr_valley = learn.lr_find().valley\n",
        "epoch = 50\n",
        "div = 25\n",
        "learn.fit_one_cycle(epoch, lr_valley, div, cbs=[EarlyStoppingCallback(monitor='valid_loss', min_delta=0.01, patience=3)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuGIO1pDvBJu"
      },
      "source": [
        "### Evaluate performance of retrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M95jgT9IvBJu",
        "outputId": "710b099c-cf16-4be2-8641-707d512929cd"
      },
      "outputs": [],
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix(figsize=(6,6))\n",
        "interp.plot_top_losses(9, figsize=(15,10)) # TODO: fix overlapping text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a custom F1 score metric for Fastai\n",
        "f1score_fastai = skm_to_fastai(f1_score, average='macro')\n",
        "\n",
        "# Append the F1 score metric\n",
        "learn.metrics.append(f1score_fastai)\n",
        "\n",
        "# Validate and print F1 Score\n",
        "val_f1score = learn.recorder.values[-1][2]  # Index 2 corresponds to the F1 score\n",
        "\n",
        "print(f\"F1 Score: {val_f1score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Automated Runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fastai.vision.all import *\n",
        "from fastcore.all import *\n",
        "from fastai.callback.tracker import EarlyStoppingCallback\n",
        "from sklearn.metrics import f1_score\n",
        "import gc \n",
        "\n",
        "path = 'data' # local\n",
        "# path = 'data5100/data' # google colab\n",
        "\n",
        "base_models = [\n",
        "    resnet18,\n",
        "    resnet50,\n",
        "    resnet152,\n",
        "    densenet121, \n",
        "    densenet201,\n",
        "]\n",
        "\n",
        "fit_options = [\n",
        "    {\"method\": \"fine_tune\", \"n_epoch\": 50}, \n",
        "    {\"method\": \"fit_one_cycle\", \"n_epoch\": 50},\n",
        "    {\"method\": \"fit_one_cycle\", \"n_epoch\": 50, \"lr_max\": \"lr_find().valley\", \"early_stop\": {\"patience\": 3}},\n",
        "    {\"method\": \"fit_one_cycle\", \"n_epoch\": 50, \"lr_max\": \"lr_find().valley\", \"div\": 10, \"early_stop\": {\"patience\": 3}}, # div 10 is per resnet paper https://arxiv.org/abs/1512.03385\n",
        "    {\"method\": \"fit_one_cycle\", \"n_epoch\": 50, \"lr_max\": \"lr_find().valley\", \"early_stop\": {\"patience\": 10}},\n",
        "]\n",
        "\n",
        "item_tfms_options = [\n",
        "    \"Resize(224)\", # using default center crop\n",
        "    \"Resize(224, pad_mode='zeros')\",\n",
        "    \"Resize(450, pad_mode='zeros')\",\n",
        "    \"RandomResizedCrop(450, min_scale=0.75)\" # from fastai paper https://arxiv.org/abs/2002.04688\n",
        "    ]\n",
        "\n",
        "batch_tfms_options = [\n",
        "    \"None\",\n",
        "    \"aug_transforms()\", \n",
        "    \"[*aug_transforms(size=224, max_warp=0.), Normalize.from_stats(*imagenet_stats)]\" # from fastai paper https://arxiv.org/abs/2002.04688\n",
        "    ]\n",
        "\n",
        "def evaluate(learner):\n",
        "    f1score_fastai = skm_to_fastai(f1_score, average='macro')\n",
        "    learner.metrics.append(f1score_fastai)\n",
        "    f1 = learner.recorder.values[-1][2] # Index 2 corresponds to the F1 score\n",
        "    return f1\n",
        "\n",
        "# Iterate over all combinations\n",
        "n = 1\n",
        "for base_model in base_models:\n",
        "    \n",
        "    # Initialize new data frame per base model, we will separate the csv because there is a chance some runs intermittently fail after a few hundred runs\n",
        "    results = pd.DataFrame(columns=[\"Base Model\", \"Fit Method\", \"n_epoch\", \"lr_max\", \"div\", \"patience\", \"item_tfms\", \"batch_tfms\", \"F1 Score\"])\n",
        "\n",
        "    for fit_option in fit_options:\n",
        "        for batch_tfms in batch_tfms_options:\n",
        "            for item_tfms in item_tfms_options:\n",
        "                print(\"######################################\")\n",
        "                print(f\"RUN: {n}\")\n",
        "                print(f\"BASE MODEL: {base_model.__name__}\") \n",
        "                print(f\"FIT OPTION: {fit_option}\")\n",
        "                print(f\"ITEM TFMS: {item_tfms}\") \n",
        "                print(f\"BATCH TFMS: {batch_tfms}\")\n",
        "                print(\"######################################\")\n",
        "                n += 1\n",
        "\n",
        "                # Data Prep\n",
        "                exec(f\"item_tfms_obj = {item_tfms}\") # Hacky way to grab the pre-evaluated option for cleaner output\n",
        "                exec(f\"batch_tfms_obj = {batch_tfms}\")\n",
        "                dls = ImageDataLoaders.from_folder(\n",
        "                    path,\n",
        "                    train='train',\n",
        "                    valid='valid',\n",
        "                    test='test',\n",
        "                    item_tfms=item_tfms_obj,\n",
        "                    batch_tfms=batch_tfms_obj,\n",
        "                    bs=32) # default batch size is 64, local runs out of memory sometimes\n",
        "                \n",
        "                # Modelling\n",
        "                learn = vision_learner(dls, base_model, metrics=error_rate)\n",
        "\n",
        "                with learn.no_bar(), learn.no_logging():\n",
        "                    lr_valley = learn.lr_find().valley if fit_option.get(\"lr_max\", None) == \"lr_find().valley\" else None;\n",
        "                    early_stop_params = fit_option.get(\"early_stop\", None)\n",
        "                    cbs = EarlyStoppingCallback(\n",
        "                        monitor='valid_loss', \n",
        "                        min_delta=0.01, \n",
        "                        patience=early_stop_params.get(\"patience\", 1) # default patience value is 1 - shouldn't get used tho\n",
        "                    ) if early_stop_params else None\n",
        "                    div = fit_option.get(\"div\", 25)\n",
        "                    if fit_option[\"method\"] == \"fit_one_cycle\":\n",
        "                        learn.fit_one_cycle(fit_option[\"n_epoch\"], lr_valley, div=div if div else None, cbs=cbs if cbs else None)\n",
        "                    if fit_option[\"method\"] == \"fine_tune\":\n",
        "                        learn.fine_tune(fit_option[\"n_epoch\"])\n",
        "\n",
        "                # Evaluation\n",
        "                f1 = evaluate(learn)\n",
        "                results = pd.concat([results, pd.DataFrame([{\n",
        "                    \"Base Model\": base_model.__name__,\n",
        "                    \"Fit Method\": fit_option[\"method\"],\n",
        "                    \"n_epoch\": fit_option[\"n_epoch\"],\n",
        "                    \"lr_max\": str(fit_option.get(\"lr_max\", None)) + f\" -> {lr_valley}\",\n",
        "                    \"div\": fit_option.get(\"div\", 25),\n",
        "                    \"patience\": fit_option[\"early_stop\"][\"patience\"] if fit_option.get(\"early_stop\", None) else 1, # TODO: TECHNICALLYYYY patience should be None in output if early stop dont exist, because it dont get used\n",
        "                    \"item_tfms\": item_tfms,\n",
        "                    \"batch_tfms\": batch_tfms,\n",
        "                    \"F1 Score\": f1\n",
        "                }])], ignore_index=True)\n",
        "                \n",
        "                # Reclaim GPU memory\n",
        "                learn = None\n",
        "                gc.collect()\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    results.to_csv(f\"{base_model.__name__}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Manually reclaim GPU memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "learn = None\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.1.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
